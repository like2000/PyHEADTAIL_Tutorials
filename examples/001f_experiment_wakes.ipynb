{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import c, e, m_p\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "%matplotlib tk\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.5,\n",
    "                rc={'lines.markeredgewidth': 1})\n",
    "sns.set_style('dark', {\n",
    "        'axes.linewidth': 2,\n",
    "        'legend.fancybox': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.wraparound(False)\n",
    "cpdef convolution_cython(double[::1] t, double[::1] x, w):\n",
    "    cdef int k, l\n",
    "    cdef double[::1] z = np.zeros(len(t))\n",
    "    for k in xrange(len(t)):\n",
    "        for l in xrange(len(t)):\n",
    "            z[k] += x[l]*w(t[k]-t[l])\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "sigma_t = 2.\n",
    "t = np.linspace(-100, 100, samples)\n",
    "x = np.exp(-t**2/(4.*sigma_t**2))\n",
    "w = lambda t: np.sin(2*np.pi*10*t)\n",
    "\n",
    "td = np.diff(t)[0]\n",
    "tl = np.concatenate((t-t[-1], (t-t[0])[1:]))\n",
    "tl = np.concatenate(((t-len(t)/2*td)[:], (t+len(t)/2*td)[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_numpy(t, x, w):\n",
    "    tmin, tmax = t[0], t[-1]\n",
    "    tt = np.concatenate((t-tmax, (t-tmin)[1:]))\n",
    "    \n",
    "    return np.convolve(x, w(tt), mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_scipy(t, x, w):\n",
    "    tmin, tmax = t[0], t[-1]\n",
    "    tt = np.concatenate((t-tmax, (t-tmin)[1:]))\n",
    "    \n",
    "    return fftconvolve(w(tt), x, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_dot(t, x, w):\n",
    "    tt = [t]-np.transpose([t])\n",
    "    \n",
    "    return np.dot(x, w(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z1 = convolution_cython(t, x, w)\n",
    "z2 = convolution_numpy(t, x, w)\n",
    "z3 = convolution_scipy(t, x, w)\n",
    "z4 = convolution_dot(t, x, w)\n",
    "\n",
    "\n",
    "plt.plot(t, z1, '-o')\n",
    "plt.plot(t, z2, '-')\n",
    "plt.plot(t, z3, '+')\n",
    "plt.plot(t, z4, '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit convolution_cython(t, x, w)\n",
    "%timeit convolution_numpy(t, x, w)\n",
    "%timeit convolution_scipy(t, x, w)\n",
    "%timeit convolution_dot(t, x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun -f convolution_cython convolution_cython(t, x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bunch creation\n",
    "\n",
    "We create a bunch - LHC type. No fancy wrapper function available yet to produce a RF matched distribution. A little tedious because it requires quite some definitions to be done beforehand of the full RF System - but that's due to the nature of the problem.\n",
    "\n",
    "- Some beam kinetic parameters and RF machine parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyHEADTAIL v1.6.0.67\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PyHEADTAIL.trackers.rf_bucket import RFBucket\n",
    "from PyHEADTAIL.particles.generators import ParticleGenerator, \\\n",
    "    gaussian2D, RF_bucket_distribution, StationaryExponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479.606062093\n"
     ]
    }
   ],
   "source": [
    "momentum = 450e9 * e/c\n",
    "gamma = np.sqrt((momentum/(m_p*c))**2 + 1)\n",
    "beta = np.sqrt(1 - gamma**-2)\n",
    "\n",
    "circumference = 26658.883\n",
    "alpha = 3.225e-4\n",
    "h1 = 35640\n",
    "V1 = 8e6\n",
    "p_increment = 0 * e/c * circumference/(beta*c)\n",
    "\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfbucket = RFBucket(\n",
    "    charge=e, mass=m_p, gamma=gamma,\n",
    "    circumference=circumference,\n",
    "    alpha_array=[alpha], p_increment=0,\n",
    "    harmonic_list=[h1], voltage_list=[V1], phi_offset_list=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = (0, 2.5e-9, 7.5e-9)\n",
    "epsn_z = (0.35, 0.25, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Maximum RMS emittance 0.888689919173eV s.\n",
      "... distance to target emittance: 2.32e-02\n",
      "... distance to target emittance: 2.34e-02\n",
      "... distance to target emittance: -5.11e-04\n",
      "... distance to target emittance: 1.04e-05\n",
      "--> Emittance: 0.350000004218\n",
      "--> Bunch length:0.0697492609648\n",
      "*** Maximum RMS emittance 0.888689919173eV s.\n",
      "... distance to target emittance: 1.69e-02\n",
      "... distance to target emittance: 1.70e-02\n",
      "... distance to target emittance: -4.02e-05\n",
      "--> Emittance: 0.250000069118\n",
      "--> Bunch length:0.0580813886211\n",
      "*** Maximum RMS emittance 0.888689919173eV s.\n",
      "... distance to target emittance: 2.45e-03\n",
      "... distance to target emittance: 2.57e-03\n",
      "... distance to target emittance: 1.73e-06\n",
      "--> Emittance: 0.100000001214\n",
      "--> Bunch length:0.0359672667212\n"
     ]
    }
   ],
   "source": [
    "bunches = [\n",
    "    ParticleGenerator(\n",
    "        macroparticlenumber=1e5, intensity=1e11,\n",
    "        charge=e, mass=m_p, gamma=gamma,\n",
    "        circumference=26658.883,\n",
    "        distribution_x=gaussian2D(2e-6),\n",
    "        distribution_y=gaussian2D(2e-6),\n",
    "        distribution_z=RF_bucket_distribution(rfbucket, epsn_z=epsn_z[i])\n",
    "    ).generate() for i in xrange(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, b in enumerate(bunches):\n",
    "    b.z -= dt[i] * (b.beta*c)\n",
    "\n",
    "bunch1, bunch2, bunch3 = bunches\n",
    "allbunches = sum(bunches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(6,6))\n",
    "# ax1.plot(bunch.x, bunch.xp, '.')\n",
    "# ax2.plot(bunch.y, bunch.yp, '.')\n",
    "# ax3.plot(bunch.z, bunch.dp, '.')\n",
    "# ax3.set_ylim(-max(abs(bunch.dp))-1e-4, max(abs(bunch.dp))+1e-4)\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(allbunches.z, allbunches.dp, '.')\n",
    "plt.xlabel(\"z [m]\")\n",
    "plt.ylabel(r\"$\\delta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wakes, slicing, convolution etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CircularResonator wake is a special resonator wake with Yokoya factors X1=1, Y1=1, X2=0, Y2=0\n",
    "\n",
    "functions transverse and longitudinal are actually meant to be used internally when building the wake kicks - at this point they are concatenated with the respective Yokoya factor being applied/provided. For visualisation we can also build them externally manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PyHEADTAIL.impedances.wakes import CircularResonator, \\\n",
    "    WakeField, check_wake_sampling\n",
    "from PyHEADTAIL.particles.slicing import UniformBinSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** PyHEADTAIL WARNING! Acceleration not handled properly by this kind of convolution due to changing bunch length!\n",
      "*** PyHEADTAIL WARNING! Acceleration not handled properly by this kind of convolution due to changing bunch length!\n"
     ]
    }
   ],
   "source": [
    "wake = CircularResonator(R_shunt=1e9, frequency=1e9, Q=20)\n",
    "slicer = UniformBinSlicer(60, z_cuts=(-.3, .3))\n",
    "\n",
    "wakefields = WakeField(slicer, wake)\n",
    "kick = wakefields.wake_kicks[0]\n",
    "wf = kick.wake_function\n",
    "\n",
    "slices, times = [], []\n",
    "for i, b in enumerate(bunches):\n",
    "    distance = dt[i]*b.beta*c\n",
    "    b.z += distance\n",
    "    slices.append(b.get_slices(slicer))\n",
    "    times.append(slices[-1].z_centers / (b.beta*c))\n",
    "    b.z -= distance\n",
    "\n",
    "slices1, slices2, slices3 = slices\n",
    "times1, times2, times3 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = sns.hls_palette(6, l=.3, s=.8)\n",
    "\n",
    "fig, axes = plt.subplots(len(slices), figsize=(12,6))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    [ax.axvline(s, c=col[0]) for s in slices[i].z_centers]\n",
    "    [ax.axvline(s, c=col[2]) for s in [slices[i].z_cut_tail, slices[i].z_cut_head]]\n",
    "    ax.plot(slices[i].z_centers, slices[i].charge_per_slice, '-o')\n",
    "    ax.set_xlim(-.4, .4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convolution_python(t_target, t_source, c_source, w):\n",
    "    dxp = 0.*t_target\n",
    "    for k in xrange(len(t_target)):\n",
    "        for l in xrange(len(t_source)):\n",
    "            dxp[k] += c_source[l]*w(t_target[k]-t_source[l])\n",
    "\n",
    "    return dxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_numpy(t, x, w):\n",
    "    tmin, tmax = t[0], t[-1]\n",
    "    tt = np.concatenate((t-tmax, (t-tmin)[1:]))\n",
    "    \n",
    "    return np.convolve(x, w(tt), mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_scipy(t, x, w):\n",
    "    tmin, tmax = t[0], t[-1]\n",
    "    tt = np.concatenate((t-tmax, (t-tmin)[1:]))\n",
    "    \n",
    "    return fftconvolve(w(tt), x, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolve_multibunch(times, moments, wf):\n",
    "    dxp = []\n",
    "    for i in xrange(len(times)):\n",
    "        t_target = times[i]\n",
    "        for j in range(i+1):\n",
    "            t_source = times[j]\n",
    "            c_source = moments[j]\n",
    "            z = convolution_python(t_target, t_source, c_source, wf)\n",
    "            \n",
    "        dxp.append(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate bunches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target-0 source-0 distance 0.000000ns\n",
      "target-1 source-0 distance 2.500000ns\n",
      "target-1 source-1 distance 0.000000ns\n",
      "target-2 source-0 distance 7.500000ns\n",
      "target-2 source-1 distance 5.000000ns\n",
      "target-2 source-2 distance 0.000000ns\n"
     ]
    }
   ],
   "source": [
    "delta_xp = []\n",
    "for i, s in enumerate(slices):\n",
    "    dxp = 0.*times[i]\n",
    "    t_target = times[i]\n",
    "    s_target = slices[i]\n",
    "    for j in range(i+1):\n",
    "        t_source = times[j] + dt[i] - dt[j]\n",
    "        s_source = slices[j]\n",
    "        print \"target-{:d} source-{:d} distance {:f}ns\".format(i, j, (dt[i]-dt[j])*1e9)\n",
    "        for k in range(s_target.n_slices):\n",
    "            for l in range(s_source.n_slices)[::+1]:\n",
    "                dxp[k] += s_source.charge_per_slice[l]*wf(\n",
    "                    t_target[k]-t_source[l])\n",
    "    delta_xp.append(dxp)\n",
    "    \n",
    "delta_xp1 = np.array(delta_xp).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 2.5e-09\n",
      "2 0 7.5e-09\n",
      "2 1 2.5e-09\n"
     ]
    }
   ],
   "source": [
    "# tt = times - times[0]\n",
    "# tt = np.concatenate((-tt[::-1], tt[1:]))\n",
    "\n",
    "dxp_list = []\n",
    "for i, s in enumerate(slices):\n",
    "    dts = times[i]\n",
    "    t0 = np.concatenate((dts-dts[-1], (dts-dts[0])[1:]))\n",
    "\n",
    "    dxp = np.convolve(s.charge_per_slice, wf(t0))\n",
    "    dxp_s = np.convolve(s.charge_per_slice, wf(t0), mode='same')\n",
    "    dxp_v = np.convolve(s.charge_per_slice, wf(t0), mode='valid')\n",
    "\n",
    "    for j in range(i):\n",
    "        print i, j, dt[i-j]\n",
    "        t_sources = times[j] + dt[i]-dt[j]\n",
    "        t2 = np.concatenate((dts-t_sources[-1], (dts-t_sources[0])[1:]))\n",
    "\n",
    "        dxp += np.convolve(slices[j].charge_per_slice, wf(t2))\n",
    "        dxp_s += np.convolve(slices[j].charge_per_slice, wf(t2), mode='same')\n",
    "        dxp_v += np.convolve(slices[j].charge_per_slice, wf(t2), mode='valid')\n",
    "    \n",
    "    dxp_list.append(dxp_v)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(12,6))\n",
    "#     fig.patch.set_color(\"#848482\")\n",
    "\n",
    "    ax1.plot(t0, wf(t0)[::-1]/max(wf(t0)[::-1]))\n",
    "    ax1.plot(dts-dts[-1]-dt[i], s.charge_per_slice/max(s.charge_per_slice))\n",
    "    ax1.set_ylim((-1.1, 1.1))\n",
    "    ax1.legend(['Bunch', 'Wake'])\n",
    "    ax1.set_xlim(-10e-9, 3e-9)\n",
    "    ax2.plot(delta_xp[i])\n",
    "    ax2.plot(dxp_v)\n",
    "    ax2.legend(['manual', 'valid'])\n",
    "    ax3.plot(dts-dts[-1], s.charge_per_slice/max(s.charge_per_slice))\n",
    "    ax3.plot(dts-dts[-1], dxp_v/max(dxp_v))\n",
    "    ax3.set_ylim(-2, 2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### All bunches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allslicer = UniformBinSlicer(400, z_cuts=(-3, .5))\n",
    "allslices = allbunches.get_slices(allslicer)\n",
    "\n",
    "alltimes = allslices.z_centers / (allbunches.beta*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_xp = 0.*alltimes\n",
    "for i, s in enumerate(allslices.charge_per_slice):\n",
    "    for j in range(allslices.n_slices)[::+1]:\n",
    "        delta_xp[i] += allslices.charge_per_slice[j]*wf(alltimes[i]-alltimes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = np.concatenate((alltimes-alltimes[-1],\n",
    "                    (alltimes-alltimes[0])[1:]))\n",
    "\n",
    "dxp = np.convolve(allslices.charge_per_slice, wf(t0))\n",
    "dxp_s = np.convolve(allslices.charge_per_slice, wf(t0), mode='same')\n",
    "dxp_v = np.convolve(allslices.charge_per_slice, wf(t0), mode='valid')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(12,10))\n",
    "\n",
    "ax1.plot(t0, wf(t0)[::-1]/max(wf(t0)[::-1]))\n",
    "ax1.plot(alltimes-alltimes[-1],\n",
    "         allslices.charge_per_slice/max(allslices.charge_per_slice))\n",
    "ax1.set_ylim((-1.1, 1.1))\n",
    "ax1.legend(['Bunch', 'Wake'])\n",
    "ax1.set_xlim(-11e-9, 3e-9)\n",
    "ax2.plot(delta_xp)\n",
    "ax2.plot(dxp_v)\n",
    "ax2.legend(['manual', 'valid'])\n",
    "\n",
    "ax3.plot(alltimes-alltimes[-1],\n",
    "         allslices.charge_per_slice/max(allslices.charge_per_slice))\n",
    "ax3.plot(alltimes-alltimes[-1], dxp_v/max(dxp_v), label=\"all bunches\")\n",
    "\n",
    "labels = [\"first bunch\", \"second bunch\", \"third bunch\"]\n",
    "scale_kick = max([max(x) for x in dxp_list])\n",
    "scale_charge = max([max(s.charge_per_slice) for s in slices])\n",
    "for i, s in enumerate(slices):\n",
    "    dts = times[i]\n",
    "    dxp = dxp_list[i]\n",
    "    dxp = delta_xp1[i]\n",
    "    ax3.plot(dts-alltimes[-1]-dt[i], s.charge_per_slice/scale_charge)\n",
    "    if i==2:\n",
    "#         ax3.plot(dts-alltimes[-1]-dt[i], dxp/scale_kick, label=labels[i], c=col[i*2])\n",
    "        ax3.plot(dts-alltimes[-1]-dt[i], dxp/max(dxp_v), label=labels[i], c=col[i*2])\n",
    "    else:\n",
    "        ax3.plot(dts-alltimes[-1]-dt[i], dxp/max(dxp_v), label=labels[i], c=col[i*2])\n",
    "\n",
    "# ax3.plot(times-times[-1]-dt, slices2.charge_per_slice/max(slices2.charge_per_slice))\n",
    "# ax3.plot(times-times[-1]-dt, dxp_v2/max(dxp_v), label=\"second bunch\")\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_xlim(-11e-9, 3e-9)\n",
    "ax3.set_ylim(-2, 2)\n",
    "\n",
    "# c = sns.color_palette('husl', 3)\n",
    "# [ax3.axvline(s, c=c[0], alpha=0.8) for s in (times-times[-1])]\n",
    "# [ax3.axvline(s, c=c[1], alpha=0.8) for s in (times2-times2[-1]-dt)]\n",
    "# [ax3.axvline(s, c=c[2], alpha=0.8) for s in (alltimes-alltimes[-1])]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
